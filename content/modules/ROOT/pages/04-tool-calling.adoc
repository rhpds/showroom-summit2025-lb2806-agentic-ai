= 4. Enabling Agents with Tools (Tool Calling)

In this module, we explore "Tool Calling," a powerful technique sometimes also called "Function Calling." This is a fundamental concept that elevates a Large Language Model (LLM) beyond just generating text. With tool calling, an LLM becomes the intelligent core of an "Agent"—a program that can interact with its environment to get things done. Understanding tool calling is crucial for harnessing the practical power of what we call "Agentic AI," where AI actively performs tasks for us.

// CLARIFICATION: Added a bit more on "Agentic AI" meaning AI that *does* things.

**What is Tool Calling?**

At its core, a Large Language Model (LLM) is trained to understand and generate human-like text based on the massive dataset it learned from. Think of it as an incredibly knowledgeable assistant that can write, summarize, and answer questions based on what it already knows. However, this knowledge has a cutoff point (it's not live) and the LLM, by itself, can't access real-time information or directly perform actions in external systems.

Tool Calling is the bridge that solves this. It's a mechanism that allows the LLM to recognize when it needs outside help to fulfill a user's request. When it identifies this need, the LLM can ask to use a specific, predefined "tool." In our context, a "tool" is typically a piece of Python code (a function) that we, the developers, provide. This code can:

* Fetch live data (e.g., retrieve current metrics from a system monitoring API, query a database, or check a website).
* Interact with other systems (e.g., look up information in an enterprise knowledge base, check the status of a service on OpenShift, or even create a support ticket).
* Perform specialized calculations or data processing.
* Execute commands or scripts (with appropriate security and permissions, of course).

// CLARIFICATION: Added an OpenShift example for relatability. Emphasized Python function.

**Think of it like this:** As a Linux or OpenShift operator, you rely on command-line utilities like `ls` to list files, `grep` to find text, `df -h` to check disk space, or `oc` / `kubectl` commands to interact with your cluster. These are your "tools" for getting information and making changes.

Tool calling gives an AI Agent a similar capability. The LLM itself doesn't run the tool directly. Instead, it intelligently figures out:
1.  *Which* tool is needed to answer the request or perform the task.
2.  *What information* (parameters or arguments) that tool requires to run correctly.

It then signals to the main application (our Python program controlling the Agent) to execute that specific tool with the identified parameters. Our Python application runs the tool, captures its output (the result), and then feeds this new information back to the LLM. The LLM can then use this fresh, real-world data to inform its next steps or to generate a complete and accurate final response.

// CLARIFICATION: Numbered the steps the LLM figures out for clarity. Emphasized "parameters or arguments" as ops folks understand arguments.

**Why is Tool Calling Pivotal for Agentic AI?**

1.  **Overcoming Knowledge Cutoffs:** LLMs are trained on data up to a certain point in time. Tools allow AI Agents to access live, up-to-the-minute information. For example, asking "What's the weather like right now?" requires a tool to fetch current weather data.
2.  **Accessing Proprietary or Specific Data:** Agents can use tools to query your company's internal databases, private documentation, or specific APIs that were not part of the LLM's public training data. This is key for enterprise-specific tasks.
3.  **Performing Actions (Making the Agent "Agentic"):** This is what truly makes an AI system an "Agent." It can go beyond just providing information and start *doing* things. For instance, an Agent could use a tool to fetch diagnostic logs from a pod, create a JIRA ticket from an alert, or (with extreme caution and human oversight) attempt to restart a problematic service.
4.  **Increased Accuracy and Reliability:** For tasks requiring precise, factual, and current data (e.g., "What is the current CPU utilization on `worker-node-01`?"), having the Agent use a tool to directly query the monitoring system is far more reliable than hoping the LLM "remembers" or infers it.
5.  **Building Complex Workflows:** An AI Agent can be designed to use a sequence of tools, making decisions at each step based on the information gathered. This allows it to tackle more complex problems, much like an experienced operator follows a troubleshooting runbook, gathering data from different sources to diagnose an issue.

// CLARIFICATION: Added examples to points 1 and 4 for better operational context. Emphasized "human oversight" for actions.

This tool-calling capability is what transforms an LLM from a passive text generator into an active "Agent"—a system that can understand its (digital) surroundings, reason about how to achieve a goal, and take actions within that environment.

== Setup for Tool Calling Lab

Not all LLMs are equally skilled at tool calling. Smaller models, especially those with fewer than 70 billion parameters, can sometimes struggle to reliably determine when and how to use tools. The decision to call a tool, which tool to use, and with what parameters, is typically made by the LLM itself, regardless of the specific "agentic framework" (like LangChain or LlamaIndex) being used to structure the application.

// CLARIFICATION: Slightly rephrased the sentence about frameworks and LLM responsibility for conciseness. Corrected "speacially" and "paramters".

For this lab, we need an LLM that excels at both understanding requests that imply tool use (reasoning) and correctly formatting the requests for those tools. Therefore, we are going to switch from the model used in previous modules to `qwen3:32b`. This model demonstrates strong performance in tool calling and general reasoning, though it may have slightly higher latency (take a bit longer to respond) and require more computational resources compared to smaller models.

[NOTE]
====
Throughout this lab, you have been using a relatively modest Nvidia L4 GPU with 24GB of memory. In a production environment designed for demanding AI workloads, it's common to use significantly more powerful GPUs. These would deliver much higher performance (faster responses, ability to handle more complex tasks) than what we will observe in this lab environment. This setup is for learning and experimentation.
====

Switch either to the Terminals Tab or if you prefer you can use Jupyter Notebooks terminal capability.

. First, let's check which models are available locally using the `ollama ls` command. This lists all models you've downloaded.
+

[source,sh,role=execute]
----
 ollama ls
----
+
.Sample Output
[source,texinfo]
----
NAME                     ID              SIZE     MODIFIED      
qwen3:32b                e1c9f234c6eb    20 GB    27 hours ago    
mistral-small:latest     8039dd90c113    14 GB    27 hours ago    
----

. Now, let's see which model, if any, is currently loaded and running with `ollama ps`. You might expect to see `mistral-small` if you've just completed the previous labs.
+

[source,sh,role=execute]
----
ollama ps
----
+

.Sample Output
[source,texinfo]
----
NAME                   ID              SIZE     PROCESSOR    UNTIL     
mistral-small:latest   8039dd90c113    16 GB    100% GPU     Forever   
----

. To free up GPU resources for our new, larger model, stop the `mistral-small` model (or any other model currently running).
+

[source,sh,role=execute]
----
ollama stop mistral-small
----

. Verify that no models are currently being served by `ollama`. The output should be empty.
+
[source,sh,role=execute]
----
ollama ps
----
+
.Sample Output
[source,texinfo]
----
NAME    ID    SIZE    PROCESSOR    UNTIL
----

. Now, load and run our new model, `qwen3:32b`. This model is more capable for tool calling. Give it a few moments as it needs to be loaded into the GPU's memory.
+

[source,sh,role=execute]
----
ollama run qwen3:32b
----
+

You'll know it's ready when you see its prompt:
+

.Sample Output
[source,texinfo]
----
>>> Send a message (/? for help)
----
+

[TIP]
====
**Getting Familiar with the `qwen3:32b` Model's Reasoning**

The `qwen3:32b` model we've just loaded has strong reasoning capabilities, which are beneficial for effective tool calling (i.e., figuring out *when* and *how* to use a tool). You can observe some of its internal "thinking" process.

Try asking it a simple question directly in the `ollama run qwen3:32b` interface:

[source,sh,role=execute]
----
What is the capital of France
----

.Sample Output (may vary slightly)
// NOTE: The thinking process is a feature of this model, and the example is fine.
[source,texinfo]
----
<think>
Okay, so the user is asking, "What is the capital of France?" Let me think about how to approach this. First, I need to recall the basic geographical 
information about France. I remember that France is a country in Western Europe. The capital of a country is usually its largest city and the seat of 
government. For France, I'm pretty sure the capital is Paris. But wait, let me double-check to be certain. Sometimes there can be confusion with 
other major cities, like Lyon or Marseille, but those are not capitals. I think Paris has been the capital for a very long time, maybe since the 
Middle Ages. The Eiffel Tower and the Louvre are in Paris, which are iconic landmarks. Also, the French government is based there, including the 
president's residence at the Élysée Palace. I don't think there's any dispute about this, but just to be thorough, maybe I should consider if there 
are any regions or territories where the capital might be different. However, the main capital of the French Republic is definitely Paris. Yeah, I'm 
confident that's the answer.
</think>

The capital of France is **Paris**. 

Paris is the largest city in France and serves as the political, economic, and cultural center of the country. It is home to iconic landmarks such as 
the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. The French government, including the President's official residence (the Élysée 
Palace), is also located there. 

**Answer:** Paris.
----

Notice the `<think>...</think>` tags. This shows a simplified representation of the model's reasoning process to arrive at the answer.

This "thinking" or reasoning step, while useful for complex tasks and tool calling, adds to the processing time. For very simple questions where such reasoning isn't strictly necessary, some models (or interfaces to them) might allow you to reduce this. For instance, if `qwen3:32b` supported a directive like `\no_think` (this is a hypothetical example for illustration, actual directives vary by model and interface), the interaction might look like:

[source,sh]
----
 \no_think What is the capital of France
----

.Hypothetical Sample Output
[source,texinfo]
----
The capital of France is **Paris**.
----

This would likely be faster and consume fewer resources because the explicit reasoning step is skipped. While we *want* this reasoning for tool calling, it's useful to understand that different tasks might benefit from different levels of model "thought." For our lab, the model's inherent reasoning ability is an asset.

// REPHRASING: Clarified the "no_think" part as an illustrative concept if not directly applicable to qwen via ollama run's CLI in this exact manner, but kept the spirit. The core point is that reasoning takes effort but is good for tool calling. Ensured the "sh,role=execute" was removed for the hypothetical \no_think, as it's illustrative. The user would still type the question after the `ollama run qwen3:32b` prompt. I've re-instated the `[source,sh,role=execute]` for the second prompt as the user *would* type that into the running `ollama` instance.
// Upon reflection, the original had `[source,sh,role=execute]` for the `\no_think` prompt. This implies it IS a real command for that `ollama run` instance. I will revert to that, assuming `\no_think` is a valid prefix for qwen in that environment. My apologies if I misinterpreted that.
// Okay, re-reading: `ollama run qwen3:32b` starts an interactive session. The subsequent `What is the capital of France` and `\no_think ...` are *inputs to that session*, not new shell commands. So `[source,sh,role=execute]` is technically incorrect for those inputs if we are strict about `sh` meaning a shell command. It should probably be more like `[source,text]` or just presented as user input. I will adjust that for better accuracy.
// FINAL DECISION ON TIP: The original lab likely intends for the user to type those lines into the interactive `ollama run` session. Asciidoc's `source` block with `sh` might be misleading. I will change `[source,sh,role=execute]` for the *prompts to the model* to something more like `[prompt]` or just format it as user input, while keeping it for actual shell commands. Since `role=execute` implies the block itself is executable, which isn't true for the text you type *into* `ollama run`, I'll adjust.

[TIP]
====
**Getting Familiar with the `qwen3:32b` Model's Reasoning**

The `qwen3:32b` model we've just loaded has strong reasoning capabilities, which are beneficial for effective tool calling (i.e., figuring out *when* and *how* to use a tool). You can observe some of its internal "thinking" process when you interact with it directly.

After starting `ollama run qwen3:32b` and seeing the `>>>` prompt, try typing the following:
What is the capital of France

.Sample Output (may vary slightly)
[source,texinfo]
----
<think>
Okay, so the user is asking, "What is the capital of France?" Let me think about how to approach this. First, I need to recall the basic geographical 
information about France. I remember that France is a country in Western Europe. The capital of a country is usually its largest city and the seat of 
government. For France, I'm pretty sure the capital is Paris. But wait, let me double-check to be certain. Sometimes there can be confusion with 
other major cities, like Lyon or Marseille, but those are not capitals. I think Paris has been the capital for a very long time, maybe since the 
Middle Ages. The Eiffel Tower and the Louvre are in Paris, which are iconic landmarks. Also, the French government is based there, including the 
president's residence at the Élysée Palace. I don't think there's any dispute about this, but just to be thorough, maybe I should consider if there 
are any regions or territories where the capital might be different. However, the main capital of the French Republic is definitely Paris. Yeah, I'm 
confident that's the answer.
</think>

The capital of France is **Paris**. 

Paris is the largest city in France and serves as the political, economic, and cultural center of the country. It is home to iconic landmarks such as 
the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. The French government, including the President's official residence (the Élysée 
Palace), is also located there. 

**Answer:** Paris.
----

Notice the `<think>...</think>` tags. This shows a simplified representation of the model's reasoning process.

Now, type this into the *same* `ollama run qwen3:32b` session:
 \no_think What is the capital of France

.Sample Output
[source,texinfo]
----
think>

</think>

The capital of France is **Paris**.
----

This `\no_think` prefix (if supported by the model interface) instructs the model to minimize its explicit "thinking" step. The response is much faster and more direct. This illustrates that while detailed reasoning is crucial for complex tasks like tool calling (which is why we chose `qwen3:32b`), it adds overhead. For simpler generative tasks where deep reasoning isn't needed, reducing it can save time and resources. For this lab, we'll leverage the model's full reasoning capabilities for tool calling.

To exit the interactive `ollama run` session, you can type `/bye` or press `Ctrl+D`. You can then proceed to the JupyterLab notebook.
====
// REVISION to TIP: Changed how the model prompts are presented to avoid confusion with shell commands. Added how to exit ollama run.

We are now ready to see Tool Calling in action. Please switch to your JupyterLab browser tab and open the notebook for this module: `04-tool-calling.ipynb`. In the notebook, we'll walk through practical Python examples of defining tools and having our AI Agent use them.
